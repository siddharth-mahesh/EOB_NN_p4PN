# hnn_class.py
"""
A Hamiltonian Neural Network (HNN) model for static and stationary geodesics.
The module generates training waveforms by integrating geodesics in a Schwarzschild-like geometry
with the metric potential A(r) (= 1 - 2M/r for Schwarzschild) generated by a Neural Network.
"""

import tensorflow as tf
from tensorflow.keras.models import Model

class HNN_Model(Model):
    """
    A Hamiltonian Neural Network model that learns a component of the Hamiltonian.
    The model's forward pass computes the corresponding waveform amplitude.
    """
    def __init__(self, nu, input_dim=1, hidden_dim=200, num_layers=2):
        """
        Initialize the HNN.

        Args:
            nu (float): The symmetric mass ratio of the binary system.
            input_dim (int): The dimension of the input space for the potential net.
            hidden_dim (int): The dimension of the hidden layers.
            num_layers (int): The number of hidden layers.
        """
        super(HNN_Model, self).__init__()
        self.nu = nu
        
        # This network learns the potential A(r) which is a part of the Hamiltonian
        layers = [tf.keras.layers.InputLayer(input_shape=(input_dim,))]
        for _ in range(num_layers):
            layers.append(tf.keras.layers.Dense(hidden_dim, activation='tanh'))
        layers.append(tf.keras.layers.Dense(1)) # Output is a single value for the potential
        self.hamiltonian_net = tf.keras.Sequential(layers, name="Potential_Net")

    @tf.function
    def call(self, z, training=False):
        """
        Define the forward pass to compute the waveform from a state vector z.
        The model returns the amplitude of the waveform.
        
        Args:
            z (tf.Tensor): State vector [r, phi, p_r, p_phi] of shape (None, 4).
            
        Returns:
            tf.Tensor: The amplitude of the waveform.
        """
        # 1. Compute time derivatives using the learned Hamiltonian
        dzdt = self._dynamics(z)
        
        # 2. Generate the waveform from the state and its derivatives
        h22_complex = self._calculate_strain(z, dzdt)
        
        return tf.abs(h22_complex)
    
    def _dynamics(self, y):
        """
        Compute the time derivatives using the learned Hamiltonian component.

        Args:
            y (tf.Tensor): State vector [r, phi, p_r, p_phi] of shape (None, 4).
            
        Returns:
            tf.Tensor: The time derivatives [dq_dt, dp_dt] of shape (None, 4).
        """
        with tf.GradientTape(persistent=True) as tape:
            tape.watch(y)
            q, p = tf.split(y, 2, axis=-1)
            # Unsqueeze r to be shape (None, 1) for the dense layer input
            r = tf.expand_dims(q[:, 0], axis=-1)
            p_r, p_phi = p[:, 0], p[:, 1]
            
            # The network learns the function A(r), which is (1 - 2M/r) in the true Hamiltonian
            a_potential = self.hamiltonian_net(r)
            a_potential = tf.squeeze(a_potential, axis=-1) # Squeeze back to (None,)

            energy_sq = a_potential * (1 + a_potential * p_r**2 + p_phi**2 / r[:, 0]**2)
            energy = tf.sqrt(energy_sq)
            
        dH_dp = tape.gradient(energy, p)
        dH_dq = tape.gradient(energy, q)
        del tape

        dq_dt = dH_dp
        dp_dt = -dH_dq
        return tf.concat([dq_dt, dp_dt], axis=-1)

    def _calculate_strain(self, ys, dydts):
        """
        Calculate the complex strain from the state and its derivatives.

        Args:
            ys (tf.Tensor): The state vector [r, phi, p_r, p_phi] of shape (None, 4).
            dydts (tf.Tensor): The time derivatives [dq_dt, dp_dt] of shape (None, 4).
            
        Returns:
            tf.Tensor: The complex strain h22 of shape (None,1).
        """

        # Split the state vector into position and momentum
        q, _ = tf.split(ys, 2, axis=-1)
        # Split the state derivatives into positional and momentum derivatives
        dqdt, _ = tf.split(dydts, 2, axis=-1)
        

        # Extract r and phi from the position vector
        r, phi = q[..., 0], q[..., 1]

        # Extract rdot and phidot from the momentum vector
        rdot, phidot = dqdt[..., 0], dqdt[..., 1]
        
        # Combine the 2,2 mode amplitude into a complex tensor
        real_part = 1 / r + r**2 * phidot**2 - rdot**2
        imag_part = 2 * self.nu * rdot * phidot
        H_22 = tf.complex(real_part, imag_part)
        
        # Calculate the complex strain h22
        h22 = 4 * self.nu * H_22 * tf.exp(tf.complex(0.0, -2.0 * phi))
        return h22
    
    def pade_1_4(self, x):
        tmp2 = ((self.a_1)*(self.a_1))
        tmp8 = ((self.a_1)*(self.a_1)*(self.a_1))
        tmp1 = 2*self.a_1*self.a_4
        tmp5 = (1.0/(((self.a_1)*(self.a_1)*(self.a_1)*(self.a_1)) + 2*self.a_1*self.a_3 - self.a_4))
        tmp7 = -self.a_1*self.a_4 + self.a_3*tmp2 + self.a_5
        pade_1_4 = (tmp5*x*(((self.a_1)*(self.a_1)*(self.a_1)*(self.a_1)*(self.a_1)) + 3*self.a_3*tmp2 + self.a_5 - tmp1) + 1)/(-self.a_1*tmp5*tmp7*((x)*(x)) + tmp5*tmp7*x + tmp5*((x)*(x)*(x)*(x))*(((self.a_3)*(self.a_3))*tmp2 - self.a_3*self.a_5 - self.a_3*tmp1 + ((self.a_4)*(self.a_4)) - self.a_5*tmp8) + tmp5*((x)*(x)*(x))*(-2*self.a_1*((self.a_3)*(self.a_3)) + self.a_3*self.a_4 - self.a_4*tmp8 + self.a_5*tmp2) + 1)
        return pade_1_4